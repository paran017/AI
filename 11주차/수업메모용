시험 = 딥러닝, 순정파계산, lstm, gru, 풀링계산, 합성곱 계산, shape들이 어떻게 변환되는지, transforme
cnn, rnn, nru, gru, transformer 등등.
금일 수업은 시험범위x.



수업시작
요즘 딥러닝의 키워드 = 생성형 모델.
생성형 모델 = Generative Model 
Manifeld learning, Representation learning 등 확산 모델 
기존의 딥러닝은 입력값에 대해 출력값을 만드는 모델을 만드는것. 그렇게 출력값과 실제값의 크로스엔트로피를, 손실함수를 줄이는것이 목적.

likelihood = 모델이 현재 데이터처럼 생긴 걸 얼마나 그럴듯하게 설명하느냐를 수치로 표현한것.
분산이 주어졌을 때 그거에 대한 데이터를 알 수 있는데, 분포에서 값이 나옴.
평균과 표준편차가 주어질 때 정규분포를 따르면 분포가 주어졌을 때 확률을 알 수 있음. 그의 반대가 likelihood임.
즉, 데이터가 주어졌을 때 그 데이터를 만족하는 확률분포가 무엇인지 맞추는것을 의미.
MLE = MAXIMUM LIKELIHOOD EMULATION. 
사이버캠퍼스 2번째거 확인.
여기서 예측된 확률분포와 실제 데이터의 확률분포의 차이를 줄이는 함수가 KL임.
이렇게 하면 좋은점이 사이버캠퍼스 3번째 링크.
그전에는 정답값으로 인해 정답값을 찾는것밖에 못하지만, 이러한 것들로 인해 산 모양의 데이터를 조금 변형해 만들 수 있음.
EX : 데이터로부터 다양하지만 살짝 다른 데이터셋을 만들 수 있음.
정답값대신 확률분포로 하면 다양한 데이터를 가질 수 있다는 말.
예를들어 미국 남자, 한국 여자의 데이터셋으로 한국 남자의 데이터셋을 만들수 있다는 의미?인듯.

오토인코더 =정보의 압축을 위한 것. 그로 인해 잠재 벡터를 만드는데 확률 분포를 설명할 수 있는 특징임. 정보의 압축에 초점이 맞춰져있음.
VARIATIONAL AUTOENCODER : 디코더에 초점이 되어있음. 인코더로 평균, 표준편차를 구한 후 입실론을 통해 데이터셋을 만들자. 즉 정보생성.

딥러닝 목적 : 데이터셋을 잘 이해할 수 있도록 분류하는것. REPRESENTATION을 다시하는것. 학습하기 쉬운 구조로. 확률분포가 잘 드러나게.

교수님 깃허브 오토인코더 예제. ㅊ = 딥러닝, 순정파계산, lstm, gru, 풀링계산, 합성곱 계산, shape들이 어떻게 변환되는지, transforme
cnn, rnn, nru, gru, transformer 등등.
금일 수업은 시험범위x.



수업시작
요즘 딥러닝의 키워드 = 생성형 모델.
생성형 모델 = Generative Model 
Manifeld learning, Representation learning 등 확산 모델 
기존의 딥러닝은 입력값에 대해 출력값을 만드는 모델을 만드는것. 그렇게 출력값과 실제값의 크로스엔트로피를, 손실함수를 줄이는것이 목적.

likelihood = 모델이 현재 데이터처럼 생긴 걸 얼마나 그럴듯하게 설명하느냐를 수치로 표현한것.
분산이 주어졌을 때 그거에 대한 데이터를 알 수 있는데, 분포에서 값이 나옴.
평균과 표준편차가 주어질 때 정규분포를 따르면 분포가 주어졌을 때 확률을 알 수 있음. 그의 반대가 likelihood임.
즉, 데이터가 주어졌을 때 그 데이터를 만족하는 확률분포가 무엇인지 맞추는것을 의미.
MLE = MAXIMUM LIKELIHOOD EMULATION. 
사이버캠퍼스 2번째거 확인.
여기서 예측된 확률분포와 실제 데이터의 확률분포의 차이를 줄이는 함수가 KL임.
이렇게 하면 좋은점이 사이버캠퍼스 3번째 링크.
그전에는 정답값으로 인해 정답값을 찾는것밖에 못하지만, 이러한 것들로 인해 산 모양의 데이터를 조금 변형해 만들 수 있음.
EX : 데이터로부터 다양하지만 살짝 다른 데이터셋을 만들 수 있음.
정답값대신 확률분포로 하면 다양한 데이터를 가질 수 있다는 말.
예를들어 미국 남자, 한국 여자의 데이터셋으로 한국 남자의 데이터셋을 만들수 있다는 의미?인듯.

오토인코더 =정보의 압축을 위한 것. 그로 인해 잠재 벡터를 만드는데 확률 분포를 설명할 수 있는 특징임. 정보의 압축에 초점이 맞춰져있음.
VARIATIONAL AUTOENCODER : 디코더에 초점이 되어있음. 인코더로 평균, 표준편차를 구한 후 입실론을 통해 데이터셋을 만들자. 즉 정보생성.

딥러닝 목적 : 데이터셋을 잘 이해할 수 있도록 분류하는것. REPRESENTATION을 다시하는것. 학습하기 쉬운 구조로. 확률분포가 잘 드러나게.

교수님 깃허브 오토인코더 예제. AE_credit.ipynb
신용카드 사용관련.
이상치 탐지를 위한 것.
27라인 피라미드 형태 등등 바꿔 해볼것.
wisdm.csv는 sitting으로 abnormal 하기.
time stamp 지우고 사람 지우기.
ecg 오토인코 예제 찾아보기. 

variationial autoencoder = 무에서 유를 창조하긴 어려움. 
교수님 깃허브 cvae.py확인

책 확인
p.681
생성형 모델
주어진 데이터로 데이터 분포 찾기
그림 13-1 확인. 특성추출해 라티드?vector찾기.
p.684
잠재벡터를 만든다는 이야기

p.694
오토인코더 생성이 노이즈 정형화
p.696 그림 13-10 기본데이터 0을 추출해서 표준편차 추출 후 앱실론값으로 generative.
p.710 그림 13-22 

p.715 코드 13-32?확인
p.716 코드 확인
코드 13-40확인

p.720 그림 확인

교수님 깃허브 imdb.ipynb확인
평론을 보고 평이 좋은지 나쁜지 구별하는 것.

spam mail classification.ipynb 스팸메일 구별.






