3주차 수업 메모

sensor데이터 
자이로스코프, 엑셀러로미터(뛰었을때 등등 측정용)
텍스트데이터 처리 practice.
센서값이 모여질때 데이터 처리하기 위한 신호를 고정된 크기로 자를수도 있고, 크기를 다르게 할 수도 있음. 
고정된 크기로 자를 때, 윈도우 크기로 자르는게 segmentation.
윈도우 사이즈를 겹쳐서 사용할 때 오버래핑이라고 함. 반정도 오버래핑될 시 50%, 겹쳐진 퍼센티지를 의미.
segmentation은 크기로 자른거, 오버래핑은 겹친것. 차이점 중요.
오버래핑은 노이즈가 생겨 못알아볼시, 뒤의 겹친 데이터로 측정 가능. 신뢰성 증가.
레이블을 결정하는 것은 그때마다 다름.(마지막것으로 결정할 것인지, 중복된 값이 많은 기준으로 결정할것인지, 등등)

본수업 시작.
파이토치 책 p.18 그림 1-1.
머신러닝과 딥러닝의 차이점 : 특성추출을 머신러닝은 인간이, 딥러닝은 컴퓨터가 진행. 
p.20~21 그림 살펴보기.
p.22 테스트 데이터셋
모델의 일반화, 훈련데이터와 테스트 데이터셋을 나누는 이유 : 모델의 일반화(예시 : gpt), train과 테스트를 나누는 이유 = 1~10까지의 데이터셋이 있고 10을 테스트로 두고 나머지로 train시 데이터셋이 같다는 확증이 없다면 확실치 않음.
즉, 모델의 일반화를 높이기 위해 test와 train을 나눠 진행.
이때 cross validation을 진행. 1~4번train, 5번 test진행. 4번 test, 1~3, 5번 train 이런식으로 진행. 즉, train데이터와 test데이터를 그룹핑 한 후에, 훈련 데이터와 테스트 데이터를 번갈아 하면서 정확도 높이기.
용어 zeroshot learning(알지 못했던 것을 알아내는 원리)
k-fold validation 알아볼것.

p.27 배치
데이터가 많을 시 한번에 처리할 데이터양을 지정하여 한 묶음으로 나누어 처리할 수 있는 것을 배치라고 함. 
p.32 전이학습, transfer learning, 등등 나중에 배움.

p.54 손실함수, 옵티마이저 용어 중요
p.86 정확도 재현율 정밀도 중요.

분류는 정확도와 재현율 구하기.
회귀는 mse 구하기.

imbalancedata 의미. (covid를 예시로, 초반 측정시 1000/10/10/30으로 볼때, 정확도는 1010/1050이나, 초반에는 false negative의 데이터 중요도가 높은 경우이고, 그에 따른 경우를 상정해야함, 즉 accurancy는 상황에 따라 중요도가 다름)
(1000/10/10/30은 각각 true positive/true negative/false positive/false negative를 의미)
imbalancedata를 위해 f1-score가 있음.

3장 시작
knn알고리즘 : k-최근접 이웃 알고리즘으로, label을 결정하는 알고리즘. 새로운 값이 들어왔을 때 최근거리의 값들을 기준으로 해당값의 label을 결정하는 것. 

서포트 벡터 : 결정 경계로 데이터를 분류하는 모델로, 기준선을 통해 데이터 분류.

결정 트리 : 데이터를 분류하거나 결괏값을 예측하는 분석 방법. 
랜덤 포레스트 : 디시전트리를 여러개 사용하는것. 앙상블모델과 부츠스트래핑모델. 앙상블은 모델을 여러개 써서 그중 좋은걸 선택해 사용하는 것을 의미. 품질이 좋다는 장점이 있으나 비용이 많이 든다는 단점.
부츠스트래핑모델은 1~5번의 예시가 있을 때 중복을 허락해 샘플을 만드는 방법. 그곳에 classifier를 적용해 결과값이 좋은것을 선택해 사용하는 것을 의미. 즉, 랜덤 포레스트는 디시전트리를 사용해 앙상블 모델을 이용하는것.

회귀 : 두 변수가 주어질 때 한 변수에서 다른 변수를 예측하거나 두 변수의 관계를 규명하는 것을 의미.

선형회귀 : 어떠한 x와 y가 있을때 x와 y에 대한 f(x)를 규명하는 것을 의미.
logistic regression : 회귀보다는 분류, 분석 대상이 여러 집단으로 나누어진 경우, 어느 집단으로 분류될 수 있는지 분석하고 이를 예측하는 모형을 개발하는데 사용되는 분류.

회귀의 평가는 MSE로 진행. 

비지도학습
K-means clustering : k-평균 군집화를 의미. 근처 데이터값들을 군집화 시키고 그것을 반복하여 군집화 된 대상들을 그룹으로 묶는 알고리즘을 의미.


